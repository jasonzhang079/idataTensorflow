{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression\n",
    "Linear regression is a method for finding the straight line or hyperplane that best fits a set of points, like simple example of (x, y).\n",
    "\n",
    "Problem is in linear model, y=wx+b, and for the data of (x, y), how can we get the answer of (W, B).\n",
    "If there are only 2 points, we can just caculated by the Linear equations. But there are thousands of (x,y), which one is correct. \n",
    "\n",
    "NOTE: try to understand it by house price prediction example, see below:\n",
    "- House Price Linear Model is to find a line that best fits a set of points(square footage, price)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/LinearRegressionHousePb.png\" style=\"width:400px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like Algebra, we define the model like:\n",
    "\n",
    "- Y1=W1X+B\n",
    "- B: bias\n",
    "- W: slope"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss Function\n",
    "How shall we evaluate if it’s a good line? \n",
    "We use Loss Function. \n",
    "<img src=\"./images/LossHousePb.png\" style=\"width:400px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That is, loss is a number indicating how bad the model's prediction was on a single example. If the model's prediction is perfect, the loss is zero; otherwise, the loss is greater. The goal of training a model is to find a set of weights and biases that have low loss, on average, across all examples.\n",
    "\n",
    "And we care about minimizing loss across our entire data set. \n",
    "\n",
    "Popular loss function: Square loss, mean square error\n",
    "- Squared Error\n",
    "L2 Loss for a given example is also called squared error\n",
    "= Square of the difference between prediction and label\n",
    "= (observation - prediction)2\n",
    "= (y - y')2\n",
    "\n",
    "L_2Loss = sum_{(x,y)\\in D} (y - prediction(x))^2\n",
    "- Mean Square Error\n",
    "measures the average of the squares of the errors or deviations. \n",
    "<img src=\"./images/SquareErrorHousePb.png\" style=\"width:300px\">\n",
    "\n",
    "\n",
    "For sure, real world should be sophisticated:\n",
    "\n",
    "y' = b + w_1x_1 + w_2x_2 + w_3x_3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "Training a model simply means learning (determining) good values for all the weights and the bias from labeled examples. In supervised learning, a machine learning algorithm builds a model by examining many examples and attempting to find a model that minimizes loss.\n",
    "\n",
    "This process is called empirical risk minimization:\n",
    "- Good weights and bias\n",
    "- Minimize the loss\n",
    "Reducing Loss\n",
    "- Convex Problem\f",
    "\n",
    "- Non-convex (eggcrate)\n",
    "It’s a iterative approach, like “Hot and Cold” kid game:\n",
    "- Initial Value: You'll start with a wild guess (\"The value of w1 is 0.\") and wait for the system to tell you what the loss is. \n",
    "- Compute Parameter Update: Then, you'll try another guess (\"The value of w1 is 0.5.\") and see what the loss is.\n",
    "\n",
    "<img src='images/Optimization.gif' style='width:400px'>\n",
    "\n",
    "\n",
    "    - Gradient descent\n",
    "        - many algorithms simply set w1 to 0 or pick a random value.\n",
    "        - The gradient descent algorithm then calculates the gradient of the loss curve at the starting point. Here in Figure 3, the gradient of loss is equal to the derivative (slope) of the curve, and tells you which way is \"warmer\" or \"colder.\" When there are multiple weights, the gradient is a vector of partial derivatives with respect to the weights.\n",
    "        - gradient is a vector, so it has both of the following characteristics:\n",
    "            - a direction\n",
    "            - a magnitude\n",
    "\n",
    "<img src='images/GradientDescent.png' style='width:400px'>\n",
    "\n",
    "    - Learning rate\n",
    "        - As noted, the gradient vector has both a direction and a magnitude. Gradient descent algorithms multiply the gradient by a scalar known as the learning rate (also sometimes called step size) to determine the next point.\n",
    "            - For example, if the gradient magnitude is 2.5 and the learning rate is 0.01, then the gradient descent algorithm will pick the next point 0.025 away from the previous point.\n",
    "\n",
    "<img src='images/LearningRateHousePb.png' style='width:400px'>\n",
    "\n",
    "    - stochastic gradient descent\n",
    "        - Stochastic gradient descent (SGD) takes this idea to the extreme--it uses only a single example (a batch size of 1) per iteration\n",
    "    - Mini-batch stochastic gradient descent\n",
    "        - is a compromise between full-batch iteration and SGD. A mini-batch is typically between 10 and 1,000 examples, chosen at random (batch size)\n",
    "\n",
    "\n",
    "Usually, you iterate until overall loss stops changing or at least changes extremely slowly. When that happens, we say that the model has converged. 模型收敛 (That minimum is where the loss function converges.)\n",
    "Many of the coding exercises contain the following hyperparameters:\n",
    "- steps, which is the total number of training iterations. One step calculates the loss from one batch and uses that value to modify the model's weights once.\n",
    "- batch size, which is the number of examples (chosen at random) for a single step. For example, the batch size for SGD is 1.\n",
    "\n",
    "\n",
    "Trick is how to make it as efficiently as possible. \n",
    "\n",
    "Again key point is, A Machine Learning model is trained by starting with an initial guess for the weights and bias and iteratively adjusting those guesses until learning the weights and bias with the lowest possible loss.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generalization\n",
    "Asking: will our model do well on a new sample of data?\n",
    "\n",
    "- Theoretically:\n",
    "    - Interesting field: generalization theory\n",
    "    - Based on ideas of measuring model simplicity / complexity\n",
    "- Intuition: formalization of Occam's Razor principle\n",
    "    - The less complex a model is, the more likely that a good empirical result is not just due to the peculiarities of our sample\n",
    "\n",
    "How do we know our model is good?\n",
    "Generalization refers to your model's ability to adapt properly to new, previously unseen data, drawn from the same distribution as the one used to create the model.\n",
    "- Develop intuition about overfitting.\n",
    "- Determine whether a model is good or not.\n",
    "- Divide a data set into a training set and a test set.\n",
    "\n",
    "Basic assumption:\n",
    "- We draw examples independently and identically (i.i.d.) at random from the distribution\n",
    "- The distribution is stationary: It doesn't change over time\n",
    "- We always pull from the same distribution: Including training, validation, and test sets\n",
    "\n",
    "In practice, we sometimes violate these assumptions. For example:\n",
    "- Consider a model that chooses ads to display. The i.i.d. assumption would be violated if the model bases its choice of ads, in part, on what ads the user has previously seen.\n",
    "- Consider a data set that contains retail sales information for a year. User's purchases change seasonally, which would violate stationarity.\n",
    "\n",
    "\n",
    "### Overfitting\n",
    "\n",
    "<img src='images/Overfitting.png' style='width:300px'>\n",
    "\n",
    "The model shown in Figures 2 and 3 overfits the peculiarities of the data it trained on. \n",
    "An overfit model gets a low loss during training but does a poor job predicting new data.\n",
    "\n",
    "Overfitting is caused by making a model more complex than necessary. \n",
    "The fundamental tension of machine learning is between fitting our data well, but also fitting the data as simply as possible. （Occam's razor - William of Occam, a 14th century friar and philosopher, loved simplicity. He believed that scientists should prefer simpler formulas or theories over more complex ones. To put Occam's razor in machine learning terms:\n",
    "The less complex an ML model, the more likely that a good empirical result is not just due to the peculiarities of the sample.）\n",
    "\n",
    "### Training / Test set \n",
    "Well, one way is to divide your data set into two subsets:\n",
    "- training set—a subset to train a model. \n",
    "- test set—a subset to test the model. \n",
    "\n",
    "Good performance on the test set is a useful indicator of good performance on the new data in general, assuming that:\n",
    "- The test set is large enough.\n",
    "- You don't cheat by using the same test set over and over.\n",
    "- Is representative of the data set as a whole. In other words, don't pick a test set with different characteristics than the training set.\n",
    "\n",
    "### Training experiences\n",
    "Never train on test data.\n",
    "Wrong approach: Tweak model according to results on Test Set -> Overfitting\n",
    "\n",
    "Better Approach: Tweak model according to result on validation \n",
    "because it creates fewer exposures to the test set.\n",
    "<img src='images/Validation.png' style='width:400px'>\n",
    "\n",
    "NOTE:\n",
    "Test sets and validation sets \"wear out\" with repeated use. That is, the more you use the same data to make decisions about hyperparameter settings or other model improvements, the less confidence you'll have that these results actually generalize to new, unseen data. Note that validation sets typically wear out more slowly than test sets.\n",
    "\n",
    "If possible, it's a good idea to collect more data to \"refresh\" the test set and validation set. Starting anew is a great reset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
